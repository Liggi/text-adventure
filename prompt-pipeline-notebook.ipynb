{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Adventure Prompt Pipeline Explorer\n",
    "\n",
    "This notebook recreates the 8-stage LLM prompt pipeline from the text adventure game, allowing you to iterate on each prompt in isolation.\n",
    "\n",
    "## Pipeline Overview\n",
    "\n",
    "**Per Turn Flow:**\n",
    "1. **Director Intent Interpretation** - Convert user input to mutations\n",
    "2. **Event Summarization** - Create canonical event lines from results\n",
    "3. **Sensory Event Generation** - Generate environmental responses\n",
    "4. **NPC Perception Filtering** - Decide what each NPC perceives\n",
    "5. **NPC Situation Summarization** - Create present-tense context\n",
    "6. **NPC Thought Generation** - Internal NPC reasoning\n",
    "7. **NPC Action Generation** - Behavioral responses\n",
    "8. **Narration** - Final storytelling layer\n",
    "\n",
    "Each stage is isolated here so you can experiment with prompt modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Helper functions loaded\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "import json\n",
    "import openai\n",
    "import os\n",
    "from typing import Dict, List, Any\n",
    "from pprint import pprint\n",
    "\n",
    "# Configure OpenAI (adjust as needed)\n",
    "openai.api_key = os.environ.get('OPENAI_API_KEY', 'your-key-here')\n",
    "\n",
    "def call_llm(system_prompt: str, user_prompt: str, model: str = \"gpt-4o-mini\", max_tokens: int = 2000) -> str:\n",
    "    \"\"\"Helper function to call LLM with consistent parameters\"\"\"\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "def call_llm_json_schema(system_prompt: str, user_prompt: str, schema: Dict[str, Any], model: str = \"gpt-4o-mini\") -> str:\n",
    "    \"\"\"Helper function for JSON schema responses\"\"\"\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            max_tokens=2000,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f'{\"error\": \"{str(e)}\"}'\n",
    "\n",
    "print(\"✅ Helper functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample World State Data\n",
    "\n",
    "This recreates the game's world state structure for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sample world data loaded\n",
      "Sample world context:\n",
      "CURRENT LOCATION: foyer\n",
      "PLAYER INVENTORY: empty\n",
      "\n",
      "LOCATION DETAILS (foyer)::\n",
      "- A dusty entrance hall with checkered tiles\n",
      "- Dim light filters through grimy windows\n",
      "\n",
      "EXITS: north to study, east to library, west to kitchen\n",
      "\n",
      "\n",
      "RECENT CONVERSATION:\n",
      "- Player: You find yourself in a dusty foyer.\n",
      "- Player: look around\n",
      "- System: You see exits to the north, east, and west.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample world state (mirrors the Go structs)\n",
    "sample_world = {\n",
    "    \"location\": \"foyer\",\n",
    "    \"inventory\": [],\n",
    "    \"met_npcs\": [],\n",
    "    \"locations\": {\n",
    "        \"foyer\": {\n",
    "            \"name\": \"foyer\",\n",
    "            \"facts\": [\"A dusty entrance hall with checkered tiles\", \"Dim light filters through grimy windows\"],\n",
    "            \"exits\": {\"north\": \"study\", \"east\": \"library\", \"west\": \"kitchen\"}\n",
    "        },\n",
    "        \"library\": {\n",
    "            \"name\": \"library\", \n",
    "            \"facts\": [\"Tall bookshelves line the walls\", \"A reading table sits in the center\"],\n",
    "            \"exits\": {\"west\": \"foyer\"}\n",
    "        },\n",
    "        \"study\": {\n",
    "            \"name\": \"study\",\n",
    "            \"facts\": [\"A wooden desk sits against the wall\", \"Papers are scattered about\"],\n",
    "            \"exits\": {\"south\": \"foyer\"}\n",
    "        },\n",
    "        \"kitchen\": {\n",
    "            \"name\": \"kitchen\",\n",
    "            \"facts\": [\"Old cabinets and a rusty sink\"],\n",
    "            \"exits\": {\"east\": \"foyer\"}\n",
    "        }\n",
    "    },\n",
    "    \"npcs\": {\n",
    "        \"elena\": {\n",
    "            \"location\": \"library\",\n",
    "            \"personality\": \"cautious, observant, struggling with disorientation\",\n",
    "            \"backstory\": \"recently awakened in this strange place with no memory of how she got here or who she was before\",\n",
    "            \"memories\": [\n",
    "                \"woke up somewhere unfamiliar\",\n",
    "                \"has no memory of her past\", \n",
    "                \"feeling disoriented and cautious\"\n",
    "            ],\n",
    "            \"facts\": [],\n",
    "            \"recent_thoughts\": [],\n",
    "            \"recent_actions\": [],\n",
    "            \"inventory\": [],\n",
    "            \"description\": \"someone\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Sample conversation history\n",
    "sample_history = [\n",
    "    \"Player: You find yourself in a dusty foyer.\",\n",
    "    \"Player: look around\",\n",
    "    \"System: You see exits to the north, east, and west.\"\n",
    "]\n",
    "\n",
    "def build_world_context(world: Dict[str, Any], history: List[str], npc_id: str = \"\") -> str:\n",
    "    \"\"\"Build world context string like the Go version\"\"\"\n",
    "    context = f\"CURRENT LOCATION: {world['location']}\\n\"\n",
    "    context += f\"PLAYER INVENTORY: {', '.join(world['inventory']) if world['inventory'] else 'empty'}\\n\\n\"\n",
    "    \n",
    "    # Location details\n",
    "    current_loc = world['locations'][world['location']]\n",
    "    context += f\"LOCATION DETAILS ({world['location']})::\\n\"\n",
    "    for fact in current_loc['facts']:\n",
    "        context += f\"- {fact}\\n\"\n",
    "    \n",
    "    context += f\"\\nEXITS: {', '.join(f'{direction} to {dest}' for direction, dest in current_loc['exits'].items())}\\n\\n\"\n",
    "    \n",
    "    # NPCs\n",
    "    current_npcs = [npc for npc_name, npc in world['npcs'].items() if npc['location'] == world['location']]\n",
    "    if current_npcs:\n",
    "        context += \"NPCs HERE:\\n\"\n",
    "        for npc in current_npcs:\n",
    "            context += f\"- {npc['description']}\\n\"\n",
    "    \n",
    "    # Add history if provided\n",
    "    if history:\n",
    "        context += f\"\\nRECENT CONVERSATION:\\n\"\n",
    "        for line in history[-5:]:  # Last 5 lines\n",
    "            context += f\"- {line}\\n\"\n",
    "    \n",
    "    return context\n",
    "\n",
    "print(\"✅ Sample world data loaded\")\n",
    "print(\"Sample world context:\")\n",
    "print(build_world_context(sample_world, sample_history))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Director Intent Interpretation\n",
    "\n",
    "The Director LLM converts natural language user input into structured mutations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 STAGE 1: Director Intent Interpretation\n",
      "User Input: 'go to the library'\n",
      "\n",
      "============================================================\n",
      "\n",
      "📋 SYSTEM PROMPT:\n",
      "You are the Director of a text adventure game. Generate only the world mutations required to fulfill the user's intent.\n",
      "\n",
      "<available_tools>\n",
      "move_player(location: string) - Move the player to a specific location\n",
      "move_npc(npc_id: string, location: string) - Move an NPC to a specific location\n",
      "transfer_item(item: string, from_location: string, to_location: string) - Move an item between locations or entities\n",
      "add_to_inventory(item: string) - Add an item from current location to player's inventory\n",
      "remove_from_inventory(item: string) - Remove an item from player's inventory to current location\n",
      "mark_npc_as_met(npc_id: string) - Mark that the player has met and learned an NPC's name\n",
      "</available_tools>\n",
      "\n",
      "<context>\n",
      "CURRENT LOCATION: foyer\n",
      "PLAYER INVENTORY: empty\n",
      "\n",
      "LOCATION DETAILS (foyer)::\n",
      "- A dusty entrance hall with checkered tiles\n",
      "- Dim light filters through grimy windows\n",
      "\n",
      "EXITS: north to study, east to library, west to kitchen\n",
      "\n",
      "\n",
      "RECENT CONVERSATION:\n",
      "- Player: You find yourself in a dusty foyer.\n",
      "- Player: look around\n",
      "- System: You see exits to the north, east, and west.\n",
      "\n",
      "</context>\n",
      "\n",
      "<guidelines>\n",
      "- Interpret the Player action and produce only necessary mutations using the available tools.\n",
      "- Output strictly as a JSON object: {\"mutations\": [ ... ]} — no extra text.\n",
      "- Be conservative; avoid speculative or unrelated changes.\n",
      "- Movement: use move_player.\n",
      "- Pick up item: use transfer_item from location → player, then add_to_inventory.\n",
      "- If meeting someone who gives their name: use mark_npc_as_met with their npc_id.\n",
      "- Drop item: remove_from_inventory, then transfer_item to current location.\n",
      "- Examine/look at environment: usually no mutations needed.\n",
      "- Examine/look at NPCs or specific items: may need mutations to trigger detailed descriptions or NPC reactions.\n",
      "- NPCs may only affect items at their location or move themselves.\n",
      "</guidelines>\n",
      "\n",
      "<example_output>\n",
      "{\"mutations\": [\n",
      "  {\"tool\": \"move_player\", \"args\": {\"location\": \"kitchen\"}},\n",
      "  {\"tool\": \"transfer_item\", \"args\": {\"item\": \"key\", \"from_location\": \"foyer\", \"to_location\": \"player\"}}\n",
      "]}\n",
      "</example_output>\n",
      "\n",
      "📝 USER PROMPT:\n",
      "Player action: go to the library\n",
      "\n",
      "🤖 LLM RESPONSE:\n",
      "{\n",
      "  \"mutations\": [\n",
      "    {\n",
      "      \"tool\": \"move_player\",\n",
      "      \"args\": {\n",
      "        \"location\": \"library\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def build_director_prompt(world: Dict[str, Any], history: List[str], acting_npc_id: str = \"\") -> str:\n",
    "    \"\"\"Build the director system prompt\"\"\"\n",
    "    \n",
    "    tool_descriptions = \"\"\"move_player(location: string) - Move the player to a specific location\n",
    "move_npc(npc_id: string, location: string) - Move an NPC to a specific location\n",
    "transfer_item(item: string, from_location: string, to_location: string) - Move an item between locations or entities\n",
    "add_to_inventory(item: string) - Add an item from current location to player's inventory\n",
    "remove_from_inventory(item: string) - Remove an item from player's inventory to current location\n",
    "mark_npc_as_met(npc_id: string) - Mark that the player has met and learned an NPC's name\"\"\"\n",
    "    \n",
    "    action_label = \"Player action\" if not acting_npc_id else f\"NPC {acting_npc_id.upper()} ACTION\"\n",
    "    \n",
    "    if acting_npc_id:\n",
    "        movement_guideline = f\"- Movement: use move_npc with npc_id=\\\"{acting_npc_id}\\\".\"\n",
    "        pickup_guidelines = f\"- Pick up item: use transfer_item from location → {acting_npc_id}.\\n- If NPC introduces themselves: use mark_npc_as_met with npc_id=\\\"{acting_npc_id}\\\".\"\n",
    "        example_destination = acting_npc_id\n",
    "    else:\n",
    "        movement_guideline = \"- Movement: use move_player.\"\n",
    "        pickup_guidelines = \"- Pick up item: use transfer_item from location → player, then add_to_inventory.\\n- If meeting someone who gives their name: use mark_npc_as_met with their npc_id.\"\n",
    "        example_destination = \"player\"\n",
    "    \n",
    "    world_context = build_world_context(world, history, acting_npc_id)\n",
    "    \n",
    "    return f\"\"\"You are the Director of a text adventure game. Generate only the world mutations required to fulfill the user's intent.\n",
    "\n",
    "<available_tools>\n",
    "{tool_descriptions}\n",
    "</available_tools>\n",
    "\n",
    "<context>\n",
    "{world_context}\n",
    "</context>\n",
    "\n",
    "<guidelines>\n",
    "- Interpret the {action_label} and produce only necessary mutations using the available tools.\n",
    "- Output strictly as a JSON object: {{\"mutations\": [ ... ]}} — no extra text.\n",
    "- Be conservative; avoid speculative or unrelated changes.\n",
    "{movement_guideline}\n",
    "{pickup_guidelines}\n",
    "- Drop item: remove_from_inventory, then transfer_item to current location.\n",
    "- Examine/look at environment: usually no mutations needed.\n",
    "- Examine/look at NPCs or specific items: may need mutations to trigger detailed descriptions or NPC reactions.\n",
    "- NPCs may only affect items at their location or move themselves.\n",
    "</guidelines>\n",
    "\n",
    "<example_output>\n",
    "{{\"mutations\": [\n",
    "  {{\"tool\": \"move_player\", \"args\": {{\"location\": \"kitchen\"}}}},\n",
    "  {{\"tool\": \"transfer_item\", \"args\": {{\"item\": \"key\", \"from_location\": \"foyer\", \"to_location\": \"{example_destination}\"}}}}\n",
    "]}}\n",
    "</example_output>\"\"\"\n",
    "\n",
    "# Test Stage 1: Director Intent Interpretation\n",
    "def test_director_stage(user_input: str, world: Dict[str, Any], history: List[str]):\n",
    "    print(f\"🎯 STAGE 1: Director Intent Interpretation\")\n",
    "    print(f\"User Input: '{user_input}'\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    system_prompt = build_director_prompt(world, history)\n",
    "    user_prompt = f\"Player action: {user_input}\"\n",
    "    \n",
    "    print(\"\\n📋 SYSTEM PROMPT:\")\n",
    "    print(system_prompt)\n",
    "    print(\"\\n📝 USER PROMPT:\")\n",
    "    print(user_prompt)\n",
    "    \n",
    "    response = call_llm_json_schema(system_prompt, user_prompt, {})\n",
    "    \n",
    "    print(\"\\n🤖 LLM RESPONSE:\")\n",
    "    try:\n",
    "        parsed = json.loads(response)\n",
    "        print(json.dumps(parsed, indent=2))\n",
    "        return parsed\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Raw response: {response}\")\n",
    "        return {\"mutations\": []}\n",
    "\n",
    "# Example test\n",
    "mutations_result = test_director_stage(\"go to the library\", sample_world, sample_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Event Summarization\n",
    "\n",
    "Creates human-readable event lines from the mutations and their results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 STAGE 2: Event Summarization\n",
      "\n",
      "============================================================\n",
      "\n",
      "📋 SYSTEM PROMPT:\n",
      "You summarize the outcome of a single game turn.\n",
      "Output the events as an array of short, human-readable lines describing what actually happened this turn.\n",
      "Use present tense. Do not invent events. It's OK if some lines describe attempts that didn't change state (like examining).\n",
      "\n",
      "📝 USER PROMPT:\n",
      "ACTOR: PLAYER\n",
      "INPUT: go to the library\n",
      "SUCCESSES:\n",
      "Player moved from foyer to library\n",
      "WORLD HINT: Location changed: foyer -> library\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid format specifier",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 30\u001b[0m, in \u001b[0;36mcall_llm_json_schema\u001b[0;34m(system_prompt, user_prompt, schema, model)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjson_object\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/_utils/_utils.py:287\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/resources/chat/completions/completions.py:1150\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1149\u001b[0m validate_response_format(response_format)\n\u001b[0;32m-> 1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_cache_key\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msafety_identifier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1185\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mverbosity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1256\u001b[0m opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1257\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1258\u001b[0m )\n\u001b[0;32m-> 1259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/_base_client.py:1047\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1046\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1047\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"'messages' must contain the word 'json' in some form, to use 'response_format' of type 'json_object'.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': None}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m new_world \u001b[38;5;241m=\u001b[39m sample_world\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     62\u001b[0m new_world[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlibrary\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 64\u001b[0m event_lines \u001b[38;5;241m=\u001b[39m \u001b[43mtest_event_summarization_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgo to the library\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_world\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_world\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPlayer moved from foyer to library\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 49\u001b[0m, in \u001b[0;36mtest_event_summarization_stage\u001b[0;34m(user_input, npc_id, old_world, new_world, successes, failures)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m📝 USER PROMPT:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(user_prompt)\n\u001b[0;32m---> 49\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mcall_llm_json_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m🤖 LLM RESPONSE:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 42\u001b[0m, in \u001b[0;36mcall_llm_json_schema\u001b[0;34m(system_prompt, user_prompt, schema, model)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid format specifier"
     ]
    }
   ],
   "source": [
    "def test_event_summarization_stage(user_input: str, npc_id: str, old_world: Dict[str, Any], new_world: Dict[str, Any], successes: List[str], failures: List[str]):\n",
    "    print(f\"📝 STAGE 2: Event Summarization\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    actor = \"PLAYER\" if not npc_id else npc_id.upper()\n",
    "    \n",
    "    world_delta_hint = \"\"\n",
    "    if old_world['location'] != new_world['location']:\n",
    "        world_delta_hint = f\"Location changed: {old_world['location']} -> {new_world['location']}\"\n",
    "    \n",
    "    user_prompt_parts = [\n",
    "        f\"ACTOR: {actor}\",\n",
    "        f\"INPUT: {user_input}\"\n",
    "    ]\n",
    "    \n",
    "    if successes:\n",
    "        user_prompt_parts.append(f\"SUCCESSES:\\n{chr(10).join(successes)}\")\n",
    "    \n",
    "    if failures:\n",
    "        user_prompt_parts.append(f\"FAILURES:\\n{chr(10).join(failures)}\")\n",
    "    \n",
    "    if world_delta_hint:\n",
    "        user_prompt_parts.append(f\"WORLD HINT: {world_delta_hint}\")\n",
    "    \n",
    "    user_prompt = \"\\n\".join(user_prompt_parts)\n",
    "    \n",
    "    schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"events\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\"type\": \"string\"},\n",
    "                \"description\": \"Array of short, human-readable lines describing what actually happened this turn\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"events\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "    \n",
    "    system_prompt = \"\"\"You summarize the outcome of a single game turn.\n",
    "Output the events as an array of short, human-readable lines describing what actually happened this turn.\n",
    "Use present tense. Do not invent events. It's OK if some lines describe attempts that didn't change state (like examining).\"\"\"\n",
    "    \n",
    "    print(\"\\n📋 SYSTEM PROMPT:\")\n",
    "    print(system_prompt)\n",
    "    print(\"\\n📝 USER PROMPT:\")\n",
    "    print(user_prompt)\n",
    "    \n",
    "    response = call_llm_json_schema(system_prompt, user_prompt, schema)\n",
    "    \n",
    "    print(\"\\n🤖 LLM RESPONSE:\")\n",
    "    try:\n",
    "        parsed = json.loads(response)\n",
    "        print(json.dumps(parsed, indent=2))\n",
    "        return parsed.get('events', [])\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Raw response: {response}\")\n",
    "        return []\n",
    "\n",
    "# Example test - simulate successful movement\n",
    "new_world = sample_world.copy()\n",
    "new_world['location'] = 'library'\n",
    "\n",
    "event_lines = test_event_summarization_stage(\n",
    "    \"go to the library\",\n",
    "    \"\",\n",
    "    sample_world,\n",
    "    new_world, \n",
    "    [\"Player moved from foyer to library\"],\n",
    "    []\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: Sensory Event Generation\n",
    "\n",
    "Generates environmental audio events that other NPCs might perceive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sensory_event_stage(user_input: str, world: Dict[str, Any], mutation_results: List[str]):\n",
    "    print(f\"👂 STAGE 3: Sensory Event Generation\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    system_prompt = \"\"\"You are a sensory event generator for a text adventure game. Generate descriptive auditory events for player actions.\n",
    "\n",
    "Rules:\n",
    "- Generate only ONE self-contained event per action\n",
    "- Events represent what happened in THIS turn only - not ongoing states\n",
    "- ONLY describe what can actually be HEARD - no visual details or object identification\n",
    "- Use complete descriptions: \"someone walked from foyer to library\" not just \"footsteps\"\n",
    "- Use objective third-person descriptions: \"someone shouted\", \"door creaking\", \"rustling sounds\"\n",
    "- Sounds cannot identify specific objects - describe the sound, not what caused it\n",
    "- Capture actual content when relevant: include spoken words, but not visual details\n",
    "- Volume levels: \"quiet\", \"moderate\", \"loud\"\n",
    "- Quiet actions like \"look around\" = no events\n",
    "\n",
    "Return JSON only:\n",
    "{\n",
    "  \"auditory_events\": [\n",
    "    {\n",
    "      \"type\": \"auditory\", \n",
    "      \"description\": \"someone shouted 'Elena, I'm here!'\",\n",
    "      \"location\": \"foyer\",\n",
    "      \"volume\": \"loud\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "If no sound, return empty auditory_events array.\"\"\"\n",
    "    \n",
    "    context_parts = [\n",
    "        f\"USER ACTION: {user_input}\",\n",
    "        f\"CURRENT LOCATION: {world['location']}\"\n",
    "    ]\n",
    "    \n",
    "    if mutation_results:\n",
    "        context_parts.append(f\"MUTATION RESULTS: {', '.join(mutation_results)}\")\n",
    "    \n",
    "    user_prompt = \"\\n\".join(context_parts)\n",
    "    \n",
    "    print(\"\\n📋 SYSTEM PROMPT:\")\n",
    "    print(system_prompt)\n",
    "    print(\"\\n📝 USER PROMPT:\")\n",
    "    print(user_prompt)\n",
    "    \n",
    "    response = call_llm_json_schema(system_prompt, user_prompt, {})\n",
    "    \n",
    "    print(\"\\n🤖 LLM RESPONSE:\")\n",
    "    try:\n",
    "        parsed = json.loads(response)\n",
    "        print(json.dumps(parsed, indent=2))\n",
    "        return parsed.get('auditory_events', [])\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Raw response: {response}\")\n",
    "        return []\n",
    "\n",
    "# Example test\n",
    "sensory_events = test_sensory_event_stage(\n",
    "    \"shout 'Hello! Is anyone there?'\",\n",
    "    sample_world,\n",
    "    [\"Player shouted in foyer\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4: NPC Perception Filtering\n",
    "\n",
    "Each NPC's LLM decides what they can perceive from the world events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_npc_perception_stage(npc_id: str, world: Dict[str, Any], world_event_lines: List[str]):\n",
    "    print(f\"👁️ STAGE 4: NPC Perception Filtering ({npc_id})\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    if not world_event_lines:\n",
    "        print(\"No world events to process\")\n",
    "        return []\n",
    "    \n",
    "    world_context = build_world_context(world, [], npc_id)\n",
    "    \n",
    "    user_prompt_parts = [\n",
    "        f\"NPC: {npc_id}\",\n",
    "        \"\",\n",
    "        f\"WORLD SNAPSHOT (for reasoning):\\n{world_context}\",\n",
    "        \"\",\n",
    "        f\"EVENT LINES:\\n{chr(10).join(world_event_lines)}\"\n",
    "    ]\n",
    "    \n",
    "    user_prompt = \"\\n\".join(user_prompt_parts)\n",
    "    \n",
    "    schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"events\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\"type\": \"string\"},\n",
    "                \"description\": \"Array of perceived event strings\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"events\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "    \n",
    "    system_prompt = \"\"\"You decide what an NPC perceives in a text adventure.\n",
    "Given a world snapshot and a list of canonical event lines from this turn, select only the lines the NPC could plausibly perceive.\n",
    "Rules:\n",
    "- Return a JSON object with an \"events\" array containing strings strictly chosen from the provided event lines.\n",
    "- Do not invent or paraphrase; copy the exact lines that would be perceived.\n",
    "- Event lines may include tags of the form \"Actor@location: ...\". Prefer selecting lines where the location matches the NPC's current room.\n",
    "- Consider location, proximity, and what could be seen or heard (e.g., speech may carry to nearby rooms; be conservative).\n",
    "- If nothing is perceived, return {\"events\": []}\"\"\"\n",
    "    \n",
    "    print(\"\\n📋 SYSTEM PROMPT:\")\n",
    "    print(system_prompt)\n",
    "    print(\"\\n📝 USER PROMPT:\")\n",
    "    print(user_prompt)\n",
    "    \n",
    "    response = call_llm_json_schema(system_prompt, user_prompt, schema)\n",
    "    \n",
    "    print(\"\\n🤖 LLM RESPONSE:\")\n",
    "    try:\n",
    "        parsed = json.loads(response)\n",
    "        print(json.dumps(parsed, indent=2))\n",
    "        return parsed.get('events', [])\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Raw response: {response}\")\n",
    "        return []\n",
    "\n",
    "# Example test - Elena in library perceiving events from foyer\n",
    "sample_events = [\n",
    "    \"Player@foyer: go to the library\",\n",
    "    \"Player moved from foyer to library\",\n",
    "    \"Footsteps approach from the foyer\"\n",
    "]\n",
    "\n",
    "perceived_events = test_npc_perception_stage(\"elena\", sample_world, sample_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 5: NPC Situation Summarization\n",
    "\n",
    "Lightweight present-tense context bridging \"what just happened\" to \"what's happening now\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_npc_situation_stage(npc_id: str, world: Dict[str, Any], perceived_lines: List[str]):\n",
    "    print(f\"🌍 STAGE 5: NPC Situation Summarization ({npc_id})\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    world_context = build_world_context(world, [], npc_id)\n",
    "    \n",
    "    user_prompt_parts = [\n",
    "        f\"<world_context>\\n{world_context.strip()}\\n</world_context>\",\n",
    "        \"\",\n",
    "        \"<perceived_events>\"\n",
    "    ]\n",
    "    \n",
    "    for event in perceived_lines:\n",
    "        user_prompt_parts.append(f\"- {event.strip()}\")\n",
    "    \n",
    "    user_prompt_parts.append(\"</perceived_events>\")\n",
    "    \n",
    "    user_prompt = \"\\n\".join(user_prompt_parts)\n",
    "    \n",
    "    system_prompt = \"\"\"Summarize the immediate situation in 1-2 short sentences in present tense.\n",
    "Use only the provided world_context and perceived_events.\n",
    "Be concrete and neutral. No invention beyond those details.\"\"\"\n",
    "    \n",
    "    print(\"\\n📋 SYSTEM PROMPT:\")\n",
    "    print(system_prompt)\n",
    "    print(\"\\n📝 USER PROMPT:\")\n",
    "    print(user_prompt)\n",
    "    \n",
    "    response = call_llm(system_prompt, user_prompt, max_tokens=1000)\n",
    "    \n",
    "    print(\"\\n🤖 LLM RESPONSE:\")\n",
    "    print(response)\n",
    "    \n",
    "    return response.strip()\n",
    "\n",
    "# Example test\n",
    "situation = test_npc_situation_stage(\"elena\", sample_world, perceived_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 6: NPC Thought Generation\n",
    "\n",
    "Internal NPC reasoning based on their character and what they've perceived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_npc_thoughts_prompt(npc_id: str, npc_data: Dict[str, Any]) -> str:\n",
    "    \"\"\"Build the NPC thoughts system prompt with XML structure\"\"\"\n",
    "    \n",
    "    prompt_parts = [f\"You are {npc_id}. Generate a single internal thought based on your current situation.\"]\n",
    "    prompt_parts.append(\"\\n<character>\")\n",
    "    prompt_parts.append(f\"- name: {npc_id}\")\n",
    "    \n",
    "    if npc_data.get('personality', '').strip():\n",
    "        prompt_parts.append(f\"- personality: {npc_data['personality']}\")\n",
    "    \n",
    "    if npc_data.get('backstory', '').strip():\n",
    "        prompt_parts.append(f\"- backstory: {npc_data['backstory']}\")\n",
    "    \n",
    "    if npc_data.get('memories', []):\n",
    "        prompt_parts.append(\"- core_memories:\")\n",
    "        for memory in npc_data['memories']:\n",
    "            prompt_parts.append(f\"  - {memory}\")\n",
    "    \n",
    "    prompt_parts.append(\"</character>\\n\")\n",
    "    \n",
    "    prompt_parts.append(\"<recent_memory>\")\n",
    "    \n",
    "    if npc_data.get('recent_thoughts', []):\n",
    "        prompt_parts.append(\"- thoughts:\")\n",
    "        for thought in npc_data['recent_thoughts']:\n",
    "            prompt_parts.append(f\"  - {thought}\")\n",
    "    \n",
    "    if npc_data.get('recent_actions', []):\n",
    "        prompt_parts.append(\"- actions:\")\n",
    "        for action in npc_data['recent_actions']:\n",
    "            prompt_parts.append(f\"  - {action}\")\n",
    "    \n",
    "    prompt_parts.append(\"</recent_memory>\\n\")\n",
    "    \n",
    "    prompt_parts.append(\"\"\"<style>\n",
    "- one line only\n",
    "- present tense; natural and practical\n",
    "- base only on world_context and perceived_events\n",
    "- no quotes; no role labels; no narration\n",
    "- avoid repeating identical prior thoughts; build on change\n",
    "- it's fine to be uncertain or to simply observe; don't force a plan\n",
    "</style>\"\"\")\n",
    "    \n",
    "    return \"\\n\".join(prompt_parts)\n",
    "\n",
    "def build_npc_thoughts_user_prompt(world_context: str, perceived_lines: List[str], situation: str) -> str:\n",
    "    \"\"\"Build the user prompt for NPC thoughts\"\"\"\n",
    "    \n",
    "    parts = [f\"<world_context>\\n{world_context.strip()}\\n</world_context>\\n\"]\n",
    "    \n",
    "    if situation.strip():\n",
    "        parts.append(f\"<situation>\\n{situation.strip()}\\n</situation>\\n\")\n",
    "    \n",
    "    parts.append(\"<perceived_events>\")\n",
    "    for event in perceived_lines:\n",
    "        parts.append(f\"- {event.strip()}\")\n",
    "    parts.append(\"</perceived_events>\")\n",
    "    \n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "def test_npc_thoughts_stage(npc_id: str, world: Dict[str, Any], perceived_lines: List[str], situation: str):\n",
    "    print(f\"🧠 STAGE 6: NPC Thought Generation ({npc_id})\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    npc_data = world['npcs'][npc_id]\n",
    "    world_context = build_world_context(world, [], npc_id)\n",
    "    \n",
    "    system_prompt = build_npc_thoughts_prompt(npc_id, npc_data)\n",
    "    user_prompt = build_npc_thoughts_user_prompt(world_context, perceived_lines, situation)\n",
    "    \n",
    "    print(\"\\n📋 SYSTEM PROMPT:\")\n",
    "    print(system_prompt)\n",
    "    print(\"\\n📝 USER PROMPT:\")\n",
    "    print(user_prompt)\n",
    "    \n",
    "    response = call_llm(system_prompt, user_prompt, max_tokens=2000)\n",
    "    \n",
    "    print(\"\\n🤖 LLM RESPONSE:\")\n",
    "    print(response)\n",
    "    \n",
    "    return response.strip()\n",
    "\n",
    "# Example test\n",
    "npc_thoughts = test_npc_thoughts_stage(\"elena\", sample_world, perceived_events, situation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 7: NPC Action Generation\n",
    "\n",
    "Generate behavioral responses based on NPC thoughts and world state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_npc_action_prompt(npc_id: str, npc_thoughts: str, npc_data: Dict[str, Any]) -> str:\n",
    "    \"\"\"Build the NPC action system prompt\"\"\"\n",
    "    \n",
    "    memory_context = \"\"\n",
    "    if npc_data.get('recent_actions', []):\n",
    "        actions_list = npc_data['recent_actions']\n",
    "        memory_context = f\"\\n\\nYour recent actions: {actions_list}\\nDon't repeat the same action unless something has changed.\"\n",
    "    \n",
    "    personality_context = \"\"\n",
    "    if npc_data.get('personality', '').strip():\n",
    "        personality_context = f\"- Personality: {npc_data['personality']}\\n\"\n",
    "    \n",
    "    backstory_context = \"\"\n",
    "    if npc_data.get('backstory', '').strip():\n",
    "        backstory_context = f\"- Background: {npc_data['backstory']}\\n\"\n",
    "    \n",
    "    return f\"\"\"You are {npc_id}. React realistically to your current situation — you don't have to \"pick an action\" every turn.\n",
    "\n",
    "Your character:\n",
    "- Name: {npc_id}\n",
    "{personality_context}{backstory_context}- You act naturally based on what you've noticed and what you're thinking\n",
    "- You can move between rooms, talk to people, interact with objects, or simply pause to observe or think\n",
    "- Only act if it makes sense right now; it's valid to call out, look around, or do nothing\n",
    "\n",
    "Your current thoughts: \"{npc_thoughts}\"{memory_context}\n",
    "\n",
    "Based on your thoughts and the world state, what do you want to do? You can:\n",
    "- Move to a different room (e.g., \"go to kitchen\") \n",
    "- Say something (e.g., \"say Hello there!\")\n",
    "- Pick up an item (e.g., \"take key\")\n",
    "- Look around or examine something (e.g., \"look around\", \"examine desk\")\n",
    "- Call out (e.g., \"say Is someone there?\")\n",
    "- Do nothing (return empty string)\n",
    "\n",
    "Return only a brief action statement, or an empty string if you don't want to act.\"\"\"\n",
    "\n",
    "def build_npc_world_context_with_perceptions(npc_id: str, world: Dict[str, Any], perceived_lines: List[str]) -> str:\n",
    "    \"\"\"Build world context with perceived events\"\"\"\n",
    "    \n",
    "    base_context = build_world_context(world, [], npc_id)\n",
    "    \n",
    "    if not perceived_lines:\n",
    "        return base_context\n",
    "    \n",
    "    perceived_section = \"PERCEIVED EVENTS:\\n\"\n",
    "    for line in perceived_lines:\n",
    "        perceived_section += f\"- {line.strip()}\\n\"\n",
    "    perceived_section += \"\\n\"\n",
    "    \n",
    "    # Insert perceived events before RECENT CONVERSATION if it exists\n",
    "    if \"RECENT CONVERSATION:\" in base_context:\n",
    "        return base_context.replace(\"RECENT CONVERSATION:\", perceived_section + \"RECENT CONVERSATION:\")\n",
    "    \n",
    "    return base_context + perceived_section\n",
    "\n",
    "def test_npc_action_stage(npc_id: str, npc_thoughts: str, world: Dict[str, Any], perceived_lines: List[str]):\n",
    "    print(f\"🎭 STAGE 7: NPC Action Generation ({npc_id})\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    if not npc_thoughts.strip():\n",
    "        print(\"No thoughts provided - skipping action generation\")\n",
    "        return \"\"\n",
    "    \n",
    "    npc_data = world['npcs'][npc_id]\n",
    "    world_context = build_npc_world_context_with_perceptions(npc_id, world, perceived_lines)\n",
    "    \n",
    "    system_prompt = build_npc_action_prompt(npc_id, npc_thoughts, npc_data)\n",
    "    user_prompt = world_context\n",
    "    \n",
    "    print(\"\\n📋 SYSTEM PROMPT:\")\n",
    "    print(system_prompt)\n",
    "    print(\"\\n📝 USER PROMPT:\")\n",
    "    print(user_prompt)\n",
    "    \n",
    "    response = call_llm(system_prompt, user_prompt, max_tokens=2000)\n",
    "    \n",
    "    print(\"\\n🤖 LLM RESPONSE:\")\n",
    "    print(response)\n",
    "    \n",
    "    return response.strip()\n",
    "\n",
    "# Example test\n",
    "npc_action = test_npc_action_stage(\"elena\", npc_thoughts, sample_world, perceived_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 8: Narration\n",
    "\n",
    "Final storytelling layer that presents the results to the player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_narration_prompt(action_context: str, mutation_results: List[str], world_event_lines: List[str]) -> str:\n",
    "    \"\"\"Build the narration system prompt\"\"\"\n",
    "    \n",
    "    action_and_mutation_context = \"\"\n",
    "    if action_context:\n",
    "        action_and_mutation_context = f\"\\n\\nACTION THAT JUST OCCURRED:\\n{action_context}\"\n",
    "        \n",
    "        if mutation_results:\n",
    "            action_and_mutation_context += \"\\n\\nWORLD CHANGES:\\n\" + \"\\n\".join(mutation_results)\n",
    "        \n",
    "        action_and_mutation_context += \"\\n\\nNarrate the consequences and results of this action.\"\n",
    "    \n",
    "    events_context = \"\"\n",
    "    if world_event_lines:\n",
    "        events_context = \"\\n\\nWORLD EVENTS FOR THIS TURN:\\n\"\n",
    "        for line in world_event_lines:\n",
    "            events_context += f\"- {line.strip()}\\n\"\n",
    "    \n",
    "    return f\"\"\"You are the narrator for an LLM-powered narrative text game. This is collaborative story-building - your role is to create an engaging story for the player to enjoy.\n",
    "\n",
    "IMPORTANT: You narrate strictly from the player's perspective. You only know what the player can directly observe, experience, or interact with. You have no omniscient knowledge about hidden details, background information, or things the player hasn't encountered.\n",
    "\n",
    "You see \"Established Facts\" for locations, items, and characters. These are canonical details that the player has already observed through previous narrations. Build naturally from these without contradicting them.\n",
    "\n",
    "If the existing facts provide enough context for the current moment, work with what's established. You may add new details when the story naturally calls for them, but only describe what the player would actually notice or experience in this moment.\n",
    "\n",
    "Your descriptions become part of the permanent world canon - anything you narrate becomes an established fact that the player has observed.\n",
    "\n",
    "Rules:\n",
    "- Base narration on the provided world events and world changes below. Focus on what happened as a result of the player's action.\n",
    "- Use present tense. Write 2-4 sentences that create a good story experience.\n",
    "- Only describe what the player can directly perceive through their senses or actions.\n",
    "- If an event contains speech, render the words as quoted dialogue.\n",
    "- If an action failed (as indicated by events/changes), briefly note why without giving advice.\n",
    "- If there are no events or changes, write a single short beat that reflects the quiet or lack of change.\n",
    "\n",
    "Only use information from the inputs below:{action_and_mutation_context}{events_context}\"\"\"\n",
    "\n",
    "def test_narration_stage(action_context: str, mutation_results: List[str], world_event_lines: List[str]):\n",
    "    print(f\"📖 STAGE 8: Narration\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    system_prompt = build_narration_prompt(action_context, mutation_results, world_event_lines)\n",
    "    user_prompt = \"Generate narration for the events described above.\"\n",
    "    \n",
    "    print(\"\\n📋 SYSTEM PROMPT:\")\n",
    "    print(system_prompt)\n",
    "    print(\"\\n📝 USER PROMPT:\")\n",
    "    print(user_prompt)\n",
    "    \n",
    "    response = call_llm(system_prompt, user_prompt, max_tokens=2000)\n",
    "    \n",
    "    print(\"\\n🤖 LLM RESPONSE:\")\n",
    "    print(response)\n",
    "    \n",
    "    return response.strip()\n",
    "\n",
    "# Example test\n",
    "final_narration = test_narration_stage(\n",
    "    \"PLAYER: go to the library\",\n",
    "    [\"Player moved from foyer to library\"],\n",
    "    [\n",
    "        \"Player@foyer: go to the library\",\n",
    "        \"Player moved from foyer to library\",\n",
    "        \"Footsteps echo from foyer to library\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Pipeline Test\n",
    "\n",
    "Run the entire 8-stage pipeline with a single user input to see the full flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_complete_pipeline(user_input: str, world: Dict[str, Any], history: List[str]):\n",
    "    print(\"🚀 COMPLETE PIPELINE TEST\")\n",
    "    print(f\"User Input: '{user_input}'\")\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    # Stage 1: Director Intent Interpretation\n",
    "    mutations_result = test_director_stage(user_input, world, history)\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    # Simulate mutation execution results\n",
    "    successes = [\"Player moved from foyer to library\"]\n",
    "    failures = []\n",
    "    new_world = world.copy()\n",
    "    new_world['location'] = 'library'\n",
    "    \n",
    "    # Stage 2: Event Summarization\n",
    "    event_lines = test_event_summarization_stage(user_input, \"\", world, new_world, successes, failures)\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    # Stage 3: Sensory Event Generation\n",
    "    sensory_events = test_sensory_event_stage(user_input, world, successes)\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    # Stage 4: NPC Perception Filtering (for Elena)\n",
    "    perceived_events = test_npc_perception_stage(\"elena\", new_world, event_lines)\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    # Stage 5: NPC Situation Summarization \n",
    "    situation = test_npc_situation_stage(\"elena\", new_world, perceived_events)\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    # Stage 6: NPC Thought Generation\n",
    "    npc_thoughts = test_npc_thoughts_stage(\"elena\", new_world, perceived_events, situation)\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    # Stage 7: NPC Action Generation\n",
    "    npc_action = test_npc_action_stage(\"elena\", npc_thoughts, new_world, perceived_events)\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    # Stage 8: Narration\n",
    "    final_narration = test_narration_stage(\n",
    "        f\"PLAYER: {user_input}\",\n",
    "        successes,\n",
    "        event_lines\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\\n\" + \"=\"*80)\n",
    "    print(\"🏁 PIPELINE COMPLETE\")\n",
    "    print(\"\\n📋 SUMMARY:\")\n",
    "    print(f\"- Mutations generated: {len(mutations_result.get('mutations', []))}\")\n",
    "    print(f\"- Event lines: {len(event_lines)}\")\n",
    "    print(f\"- Elena perceived: {len(perceived_events)} events\")\n",
    "    print(f\"- Elena's thought: '{npc_thoughts}'\")\n",
    "    print(f\"- Elena's action: '{npc_action}'\")\n",
    "    print(f\"- Final narration: '{final_narration[:100]}...'\")\n",
    "\n",
    "# Run complete test\n",
    "run_complete_pipeline(\"go to the library\", sample_world, sample_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation Section\n",
    "\n",
    "Use the cells below to experiment with individual stages or test different scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different user inputs\n",
    "experimental_inputs = [\n",
    "    \"look around\",\n",
    "    \"shout 'Elena! Where are you?'\",\n",
    "    \"examine the dusty tiles\",\n",
    "    \"go north to the study\",\n",
    "    \"say hello to anyone nearby\"\n",
    "]\n",
    "\n",
    "for test_input in experimental_inputs:\n",
    "    print(f\"\\n🧪 TESTING: '{test_input}'\")\n",
    "    print(\"-\" * 50)\n",
    "    mutations = test_director_stage(test_input, sample_world, sample_history)\n",
    "    print(f\"Generated {len(mutations.get('mutations', []))} mutations\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with NPC behavior in different scenarios\n",
    "test_scenarios = [\n",
    "    {\n",
    "        \"perceived_events\": [\"Player@library: Hello Elena!\"],\n",
    "        \"description\": \"Player greets Elena directly\"\n",
    "    },\n",
    "    {\n",
    "        \"perceived_events\": [\"Loud crash from foyer\", \"Glass shattering sounds\"],\n",
    "        \"description\": \"Alarming sounds from adjacent room\"\n",
    "    },\n",
    "    {\n",
    "        \"perceived_events\": [],\n",
    "        \"description\": \"Complete silence - no events\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for scenario in test_scenarios:\n",
    "    print(f\"\\n🎭 SCENARIO: {scenario['description']}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    situation = test_npc_situation_stage(\"elena\", sample_world, scenario['perceived_events'])\n",
    "    thoughts = test_npc_thoughts_stage(\"elena\", sample_world, scenario['perceived_events'], situation)\n",
    "    action = test_npc_action_stage(\"elena\", thoughts, sample_world, scenario['perceived_events'])\n",
    "    \n",
    "    print(f\"\\n💭 Result - Thought: '{thoughts}'\")\n",
    "    print(f\"🎯 Result - Action: '{action}'\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
